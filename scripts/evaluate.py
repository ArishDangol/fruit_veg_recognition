# import torch
# import torchvision
# import torchvision.transforms as transforms
# from torch.utils.data import DataLoader
# from models.custom_cnn import FruitVegCNN
# import sys
# import os

# # ‚úÖ Fix Import Issue
# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# # ‚úÖ Load the Trained Model
# model = FruitVegCNN(num_classes=131)
# model.load_state_dict(torch.load("./saved_models/best_model.pth", map_location=torch.device('cpu')))
# model.eval()

# # ‚úÖ Data Preprocessing (Updated to 64x64)
# transform = transforms.Compose([
#     transforms.Resize((64, 64)),  
#     transforms.ToTensor(),
#     transforms.Normalize((0.5,), (0.5,))
# ])

# # ‚úÖ Load Test Dataset
# testset = torchvision.datasets.ImageFolder(root='./dataset_fruit_360/test', transform=transform)
# testloader = DataLoader(testset, batch_size=32, shuffle=False)

# # ‚úÖ Evaluate Model Accuracy
# correct = 0
# total = 0
# with torch.no_grad():
#     for images, labels in testloader:
#         outputs = model(images)
#         _, predicted = torch.max(outputs, 1)           # ‚úÖ Softmax selects the highest probability class
#         total += labels.size(0)
#         correct += (predicted == labels).sum().item()

# accuracy = 100 * correct / total
# print(f'‚úÖ Model Evaluation Completed! Accuracy: {accuracy:.2f}%')


# #optimzed code 
# import torch
# import torchvision
# import torchvision.transforms as transforms
# from torch.utils.data import DataLoader
# from models.custom_cnn import FruitVegCNN
# import sys
# import os

# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# # ‚úÖ Load Trained Model
# model = FruitVegCNN(num_classes=131).to(device)
# model.load_state_dict(torch.load("./saved_models/best_model.pth", map_location=device))
# model.eval()

# # ‚úÖ Preprocessing (Consistent with Training)
# transform = transforms.Compose([
#     transforms.Resize((100, 100)),  
#     transforms.ToTensor(),
#     transforms.Normalize((0.5,), (0.5,))
# ])

# # ‚úÖ Load Test Dataset
# testset = torchvision.datasets.ImageFolder(root='./dataset_fruit_360/test', transform=transform)
# testloader = DataLoader(testset, batch_size=64, shuffle=False)

# # ‚úÖ Evaluate Model
# correct = 0
# total = 0
# with torch.no_grad():
#     for images, labels in testloader:
#         images, labels = images.to(device), labels.to(device)
#         outputs = model(images)
#         _, predicted = torch.max(outputs, 1)  
#         total += labels.size(0)
#         correct += (predicted == labels).sum().item()

# accuracy = 100 * correct / total
# print(f'‚úÖ Model Evaluation Completed! Accuracy: {accuracy:.2f}%')


# #‚úÖ CPU-Optimized Evaluation Code
# import torch
# import torchvision
# import torchvision.transforms as transforms
# from torch.utils.data import DataLoader
# from models.custom_cnn import FruitVegCNN
# import sys
# import os
# from tqdm import tqdm  # ‚úÖ Progress bar

# # ‚úÖ Fix Import Issues
# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# # ‚úÖ Force CPU Mode (No GPU)
# device = torch.device("cpu")  # üöÄ Now using ONLY CPU

# # ‚úÖ Load Model
# model = FruitVegCNN(num_classes=131).to(device)
# model.load_state_dict(torch.load("./saved_models/best_model.pth", map_location=device))
# model.eval()

# # ‚úÖ Data Preprocessing (Matches Training)
# transform = transforms.Compose([
#     transforms.Resize((100, 100)),  
#     transforms.ToTensor(),
#     transforms.Normalize((0.5,), (0.5,))
# ])

# # ‚úÖ Load Test Dataset
# testset = torchvision.datasets.ImageFolder(root='./dataset_fruit_360/test', transform=transform)

# # ‚úÖ Reduce Batch Size for CPU (Speeds Up Processing)
# testloader = DataLoader(testset, batch_size=32, shuffle=False)  

# # ‚úÖ Evaluate Model with Progress Bar
# correct = 0
# total = 0

# print("üîé Evaluating Model (CPU Mode)...")
# with torch.no_grad():
#     for images, labels in tqdm(testloader, desc="‚è≥ Processing Batches"):
#         images, labels = images.to(device), labels.to(device)
#         outputs = model(images)
#         _, predicted = torch.max(outputs, 1)  
#         total += labels.size(0)
#         correct += (predicted == labels).sum().item()

# # ‚úÖ Display Final Accuracy
# accuracy = 100 * correct / total
# print(f'üéØ Model Evaluation Completed! Accuracy: {accuracy:.2f}% ‚úÖ')





#‚úÖ CPU-Optimized Evaluation Code
import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from models.custom_cnn import FruitVegCNN
import sys
import os
from tqdm import tqdm  # ‚úÖ Progress bar

# ‚úÖ Fix Import Issues
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# ‚úÖ Force CPU Mode (No GPU)
device = torch.device("cpu")  # üöÄ Now using ONLY CPU

# ‚úÖ Load Model
model = FruitVegCNN(num_classes=54).to(device)
model.load_state_dict(torch.load("./saved_models/best_model.pth", map_location=device))
model.eval()

# ‚úÖ Data Preprocessing (Matches Training)
transform = transforms.Compose([
    transforms.Resize((100, 100)),  
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# ‚úÖ Load Test Dataset
testset = torchvision.datasets.ImageFolder(root='./dataset_fruit_360/test', transform=transform)

# ‚úÖ Reduce Batch Size for CPU (Speeds Up Processing)
testloader = DataLoader(testset, batch_size=32, shuffle=False)  

from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# ‚úÖ After your prediction loop:
y_true = []
y_pred = []

with torch.no_grad():
    for images, labels in tqdm(testloader, desc="‚è≥ Processing Batches"):
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)

        y_true.extend(labels.cpu().numpy())
        y_pred.extend(predicted.cpu().numpy())

# ‚úÖ Classification Report
print("\nüìÑ Classification Report:")
print(classification_report(y_true, y_pred))

# ‚úÖ Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(12, 10))
sns.heatmap(cm, cmap="Blues", xticklabels=testset.classes, yticklabels=testset.classes, annot=False, fmt="d")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("üçì Confusion Matrix")
plt.tight_layout()
plt.show()
